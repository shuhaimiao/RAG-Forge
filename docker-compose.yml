services:
  ollama:
    build:
      context: .
      dockerfile: ollama.Dockerfile
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    container_name: ollama
    environment:
      - OLLAMA_MODELS_TO_PULL=dengcao/Qwen3-Embedding-0.6B:Q8_0,qwen3:1.7b
    healthcheck:
      test: |
        (
          curl -s --fail http://localhost:11434/api/tags | grep -q 'dengcao/Qwen3-Embedding-0.6B:Q8_0' &&
          curl -s --fail http://localhost:11434/api/tags | grep -q 'qwen3:1.7b'
        ) || exit 1
      interval: 10s
      timeout: 5s
      retries: 20

  postgres:
    image: pgvector/pgvector:pg16
    container_name: postgres
    environment:
      POSTGRES_DB: rag-forge
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d rag-forge"]
      interval: 10s
      timeout: 5s
      retries: 5

  app:
    build: .
    ports:
      - "8000:8000" # FastAPI
      - "8501:8501" # Streamlit
    volumes:
      - ./src:/app/src
      - ./.secrets:/app/.secrets
    environment:
      # PostgreSQL settings
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=rag-forge
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      # Ollama settings
      - OLLAMA_HOST=http://ollama:11434
      - EMBEDDING_MODEL=dengcao/Qwen3-Embedding-0.6B:Q8_0
      - LLM_MODEL=qwen3:1.7b
      # LLM Provider
      - LLM_PROVIDER=github_copilot
      - GITHUB_COPILOT_TOKEN_PATH=/app/.secrets/github_token.json
    depends_on:
      postgres:
        condition: service_healthy
      ollama:
        condition: service_healthy
    container_name: rag-forge-app
    healthcheck:
      test: ["CMD", "test", "-f", "/tmp/ready"]
      interval: 5s
      timeout: 3s
      retries: 10

volumes:
  ollama_data:
  postgres_data: 